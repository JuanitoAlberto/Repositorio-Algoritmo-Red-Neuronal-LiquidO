import uproot
import ROOT
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import os
import sys
from tensorflow.keras.models import load_model
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc

# ===================================================================================
# 1. CONFIGURACI√ìN Y CONFIGURACI√ìN B√ÅSICA
# ===================================================================================
# 1.1. Importaciones
# ------------------------------------------------------------------------------------
# Importaciones necesarias para el an√°lisis y visualizaci√≥n
def clear_output(wait=False):
    """Limpia la salida de la consola de forma multiplataforma."""
    # Para Windows
    if os.name == 'nt':
        os.system('cls')
    # Para Unix/Linux/MacOS
    else:
        os.system('clear')
    
    # Si estamos en un notebook de Jupyter, tambi√©n intentamos usar IPython
    try:
        from IPython.display import clear_output as ipy_clear
        ipy_clear(wait=wait)
    except ImportError:
        pass

# Importaciones adicionales
import joblib
import os
import time
import argparse

# OPCIONAL: Si tienes problemas con la GPU y quieres forzar el uso de CPU
# Descomenta las siguientes dos l√≠neas ANTES de importar tensorflow o keras
# import os
# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# ===================================================================================
# 2. CONFIGURACI√ìN DEL PROGRAMA
# ===================================================================================
# 2.1. Rutas y archivos
# ------------------------------------------------------------------------------------
MODEL_PATH = "particle_classifier_model.keras"  # Ruta al modelo entrenado
SCALER_PATH = "data_scaler.pkl"              # Ruta al scaler usado durante el entrenamiento
INPUT_ROOT_FILE = "clasificable.root"         # Archivo ROOT con los datos a predecir
TREE_NAME = "feature_tree"                    # Nombre del √°rbol en el archivo ROOT que contiene las caracter√≠sticas

# 2.2. Caracter√≠sticas del modelo
FEATURE_COLUMNS = [
    "Ec1",     # Energ√≠a del cluster principal
    "Ec2",     # Energ√≠a del segundo cluster m√°s grande
    "Qmx",     # Carga m√°xima
    "QmxP",    # Carga m√°xima en z > 0
    "QmxM",    # Carga m√°xima en z < 0
    "tminP",   # Tiempo m√≠nimo en z > 0
    "tminM",   # Tiempo m√≠nimo en z < 0
    "dp",      # Diferencia de tiempo entre z > 0 y z < 0
    "Qmx2_val", # Valor de la carga m√°xima
    "Qtot_p",  # Carga total en z > 0
    "Qtot_m",  # Carga total en z < 0
    "nhits_fired_sipm"  # N√∫mero de SiPMs disparados
]

# ===================================================================================
# 3. CONFIGURACI√ìN DE AN√ÅLISIS DE ENERG√çA
# ===================================================================================
# 3.1. Intervalos de energ√≠a en MeV
EK_INTERVALS = [
    (0, 1),           # 0-1 MeV
    (1, 3),           # 1-3 MeV
    (3, float('inf')) # >3 MeV
]

# 3.3. Funciones auxiliares de energ√≠a
def get_ek_interval(ek):
    """
    Determina el intervalo de energ√≠a al que pertenece un evento.
    
    Args:
        ek: Energ√≠a cin√©tica del evento
        
    Returns:
        √çndice del intervalo (0-4) o -1 si est√° fuera de rango
    """
    for i, (low, high) in enumerate(EK_INTERVALS):
        if low <= ek < high:
            return i
    return -1  # Fuera de rango


def get_ek_center(interval_idx):
    """
    Obtiene el valor central de un intervalo de energ√≠a.
    
    Args:
        interval_idx: √çndice del intervalo (0-4)
        
    Returns:
        Valor central del intervalo o None si el √≠ndice es inv√°lido
    """
    if 0 <= interval_idx < len(EK_INTERVALS):
        low, high = EK_INTERVALS[interval_idx]
        return (low + high) / 2
    return None


# ===================================================================================
# 4. MAPEO DE ETIQUETAS
# ===================================================================================
# 4.1. Mapeo de predicciones del modelo
# ------------------------------------------------------------------------------------
LABEL_TO_PARTICLE = {
    0: "Electr√≥n",
    1: "Positr√≥n",
    2: "Gamma"
}

# 4.2. Mapeo de PDG ID para etiquetas reales
PDG_TO_PARTICLE = {
    11: "Electr√≥n",
    -11: "Positr√≥n",
    22: "Gamma"
}

# ===================================================================================
# 5. VISUALIZACI√ìN DE RESULTADOS
# ===================================================================================
# ------------------------------------------------------------------------------------
def display_histograms(event_idx, hist_zp, hist_zm, pred_label, true_label, confidence):
    """Muestra los histogramas de carga para un evento."""
    plt.figure(figsize=(14, 6))
    
    # Configurar t√≠tulo general
    title = f'Evento {event_idx} - Predicci√≥n: {pred_label} ({confidence*100:.1f}%)'
    if true_label:
        title += f' | Real: {true_label}'
    plt.suptitle(title, fontsize=14, fontweight='bold')
    
    # Mostrar histograma z > 0
    if hist_zp is not None:
        plt.subplot(1, 2, 1)
        plt.imshow(hist_zp.values().T, 
                  extent=[-900, 900, -900, 900], 
                  origin='lower', 
                  norm=LogNorm(vmin=1, vmax=hist_zp.values().max()),
                  cmap='viridis')
        plt.colorbar(label='Carga')
        plt.title('Plano z > 0')
        plt.xlabel('X (mm)')
        plt.ylabel('Y (mm)')
    
    # Mostrar histograma z < 0
    if hist_zm is not None:
        plt.subplot(1, 2, 2)
        plt.imshow(hist_zm.values().T,
                  extent=[-900, 900, -900, 900],
                  origin='lower',
                  norm=LogNorm(vmin=1, vmax=hist_zm.values().max()),
                  cmap='viridis')
        plt.colorbar(label='Carga')
        plt.title('Plano z < 0')
        plt.xlabel('X (mm)')
        plt.ylabel('Y (mm)')
    
    plt.tight_layout()
    plt.show(block=False)
    plt.pause(0.1)  # Dar tiempo para que se muestre la figura

# ===================================================================================
# 6. FUNCI√ìN PRINCIPAL DE CLASIFICACI√ìN
# ===================================================================================

def classify_events(model_path, scaler_path, input_file, tree_name, feature_columns, 
                   max_events=None, show_histograms_flag=True, prob_threshold=0.0):
    """
    Clasifica eventos de part√≠culas usando un modelo de red neuronal entrenado.
    
    Realiza la carga del modelo, preprocesamiento de datos, predicci√≥n y an√°lisis
    de resultados, incluyendo m√©tricas de rendimiento y visualizaciones.
    
    Args:
        model_path (str): Ruta al archivo del modelo Keras guardado (.keras o .h5)
        scaler_path (str): Ruta al archivo del escalador guardado (.pkl)
        input_file (str): Ruta al archivo ROOT de entrada con los datos
        tree_name (str): Nombre del √°rbol en el archivo ROOT que contiene los datos
        feature_columns (list): Lista de nombres de caracter√≠sticas a utilizar
        max_events (int, opcional): N√∫mero m√°ximo de eventos a procesar
        show_histograms_flag (bool): Si es True, muestra histogramas de eventos
        prob_threshold (float): Umbral de probabilidad [0-1] para filtrar predicciones
        
    Returns:
        None: Los resultados se muestran por consola y en gr√°ficos
    """
    
    # ===========================================================================
    # 6.1. INICIALIZACI√ìN Y CARGA DE RECURSOS
    # ===========================================================================
    file = None  # Variable para el archivo ROOT
    
    try:
        # -------------------------------------------------------------------
        # 6.1.1. Cargar el modelo de red neuronal
        # -------------------------------------------------------------------
        try:
            model = load_model(model_path)
            print(f"‚úÖ Modelo cargado exitosamente: {os.path.basename(model_path)}")
        except Exception as e:
            print(f"‚ùå Error al cargar el modelo desde '{model_path}': {e}")
            return

        # -------------------------------------------------------------------
        # 6.1.2. Cargar el escalador de caracter√≠sticas
        # -------------------------------------------------------------------
        try:
            scaler = joblib.load(scaler_path)
            print(f"‚úÖ Scaler cargado exitosamente: {os.path.basename(scaler_path)}")
        except Exception as e:
            print(f"‚ùå Error al cargar el scaler desde '{scaler_path}': {e}")
            return

        # ===================================================================
        # 6.2. CARGA Y PREPARACI√ìN DE DATOS
        # ===================================================================
        try:
            # -------------------------------------------------------------------
            # 6.2.1. Cargar datos del archivo ROOT
            # -------------------------------------------------------------------
            print(f"\nüìÇ Cargando datos desde: {input_file}")
            file = uproot.open(input_file)
            
            # Verificar si el √°rbol existe
            if tree_name not in file:
                print(f"‚ùå Error: No se encontr√≥ el √°rbol '{tree_name}' en el archivo")
                return
                
            tree = file[tree_name]
            
            # -------------------------------------------------------------------
            # 6.2.2. Verificar y cargar histogramas si es necesario
            # -------------------------------------------------------------------
            show_histograms = False
            if show_histograms_flag:
                histo_dir = file.get("histogramas")
                if histo_dir is not None:
                    show_histograms = True
                    print("‚úÖ Histogramas disponibles para visualizaci√≥n")
                else:
                    print("‚ö†Ô∏è  Advertencia: No se encontr√≥ el directorio 'histogramas'")
            
            # -------------------------------------------------------------------
            # 6.2.3. Cargar caracter√≠sticas y etiquetas
            # -------------------------------------------------------------------
            print(f"üìä Cargando caracter√≠sticas: {', '.join(feature_columns)}")
            
            # Cargar caracter√≠sticas principales del feature_tree
            # Cargar datos en un DataFrame de pandas
            print(f"\nüì• Cargando datos desde {input_file}...")
            df = tree.arrays(feature_columns + ["mcpdg", "event_number"], library="pd")
            print(f"   - Total eventos cargados: {len(df)} (event_number: {df['event_number'].min()} a {df['event_number'].max()})")
            
            # Cargar mcke del √°rbol output si existe
            if 'output' in file:
                output_tree = file['output']
                try:
                    mcke_data = output_tree.arrays(["mcke"], library="pd")['mcke']
                    # Asegurarse de que las longitudes coincidan
                    if len(mcke_data) >= len(df):
                        df['mcke'] = mcke_data.values[:len(df)]
                        print("‚úÖ mcke cargado correctamente del √°rbol 'output'")
                    else:
                        print("‚ö†Ô∏è  Advertencia: El √°rbol 'output' tiene menos eventos que 'feature_tree'")
                        df = df.iloc[:len(mcke_data)]
                        print(f"   - Eventos despu√©s de igualar con mcke_data: {len(df)}")
                        df['mcke'] = mcke_data.values
                except Exception as e:
                    print(f"‚ö†Ô∏è  No se pudo cargar 'mcke' del √°rbol 'output': {e}")
                    df['mcke'] = 0.0  # Valor por defecto
            else:
                print("‚ö†Ô∏è  No se encontr√≥ el √°rbol 'output' para cargar 'mcke'")
                df['mcke'] = 0.0  # Valor por defecto

            # -------------------------------------------------------------------
            # 6.2.4. Limitar el n√∫mero de eventos manualmente si es necesario
            # -------------------------------------------------------------------
            if max_events is not None and max_events > 0 and len(df) > max_events:
                df = df.head(max_events)

                print(f"üî¢ Se procesar√°n {max_events} eventos (de {len(df)} disponibles)")
            else:
                print(f"üî¢ Se procesar√°n todos los eventos: {len(df)}")
                
        except Exception as e:
            print(f"‚ùå Error al cargar el archivo ROOT: {e}")
            return
        
        # ===================================================================
        # 6.3. PREPROCESAMIENTO DE DATOS
        # ===================================================================
        print("\nüîß Preprocesando datos...")
        
        # -------------------------------------------------------------------
        # 6.3.1. Extraer y escalar caracter√≠sticas
        # -------------------------------------------------------------------
        X = df[feature_columns].values
        X_scaled = scaler.transform(X)
        
        # ===================================================================
        # 6.4. PREDICCI√ìN
        # ===================================================================
        print("\nüß† Realizando predicciones...")
        
        # -------------------------------------------------------------------
        # 6.4.1. Realizar predicciones y normalizar probabilidades
        # -------------------------------------------------------------------
        probabilities = model.predict(X_scaled, verbose=0)
        probabilities = probabilities / np.sum(probabilities, axis=1, keepdims=True)
        
        # -------------------------------------------------------------------
        # 6.4.2. Procesar resultados de predicci√≥n
        # -------------------------------------------------------------------
        predicted_labels = np.argmax(probabilities, axis=1)
        confidence_scores = np.max(probabilities, axis=1)
        
        # ===================================================================
        # 6.5. AN√ÅLISIS DE RESULTADOS
        # ===================================================================

        # Crear carpeta Plots para guardar las figuras (si no existe)
        plots_dir = 'Plots'
        if not os.path.exists(plots_dir):
            os.makedirs(plots_dir)
            print(f"\nCreada carpeta '{plots_dir}' para guardar las figuras")
                
        if 'mcpdg' in df.columns:
            print("\nüìä Analizando resultados...")
            
            # -------------------------------------------------------------------
            # 6.5.1. Mapear c√≥digos PDG a etiquetas num√©ricas
            # -------------------------------------------------------------------
            def map_pdg_to_label(pdg_code):
                """
                Convierte c√≥digos PDG a etiquetas num√©ricas.
                
                Args:
                    pdg_code: C√≥digo PDG de la part√≠cula
                    
                Returns:
                    int: 0 (e-), 1 (e+), 2 (gamma) o -1 (desconocido)
                """
                if pdg_code == 11: return 0    # Electr√≥n
                if pdg_code == -11: return 1   # Positr√≥n
                if pdg_code == 22: return 2    # Gamma
                return -1  # PDG no reconocido
            
            # -------------------------------------------------------------------
            # 6.5.2. Filtrar eventos con PDG reconocido
            # -------------------------------------------------------------------
            # Mapear c√≥digos PDG y filtrar solo los reconocidos
            true_labels = df['mcpdg'].apply(map_pdg_to_label)
            valid_pdg_mask = true_labels != -1
            
            # Obtener los event_numbers originales
            event_numbers = df['event_number'].values
            
            # Aplicar m√°scara de PDG v√°lido a todos los arrays
            true_labels = true_labels[valid_pdg_mask].copy()
            predicted_labels = predicted_labels[valid_pdg_mask]
            confidence_scores = confidence_scores[valid_pdg_mask]
            probabilities = probabilities[valid_pdg_mask]
            mcke_values = df['mcke'].values[valid_pdg_mask].copy()
            filtered_event_numbers = event_numbers[valid_pdg_mask].copy()
            
            # Inicializar versiones filtradas (sin umbral aplicado)
            filtered_true_labels = true_labels.copy()
            filtered_predicted_labels = predicted_labels.copy()
            filtered_confidence_scores = confidence_scores.copy()
            filtered_probabilities = probabilities.copy()
            filtered_mcke_values = mcke_values.copy()
            
            # -------------------------------------------------------------------
            # 6.5.3. Aplicar umbral de probabilidad si es necesario
            # -------------------------------------------------------------------
            if prob_threshold > 0.0:
                print(f"\n[DEBUG] Antes del filtrado - Eventos totales: {len(true_labels)}")
                print(f"\n[DEBUG] Aplicando umbral de {prob_threshold*100}%...")
                # Crear m√°scara para eventos que superan el umbral
                above_threshold = confidence_scores >= prob_threshold
                
                if np.any(above_threshold):
                    # Actualizar versiones filtradas
                    filtered_true_labels = true_labels[above_threshold].copy()
                    filtered_predicted_labels = predicted_labels[above_threshold].copy()
                    filtered_confidence_scores = confidence_scores[above_threshold].copy()
                    filtered_probabilities = probabilities[above_threshold].copy()
                    filtered_mcke_values = mcke_values[above_threshold].copy()
                    filtered_event_numbers = filtered_event_numbers[above_threshold].copy()
                    
                    # Estad√≠sticas
                    n_filtered = len(filtered_true_labels)
                    n_total = len(true_labels)
                    print(f"[DEBUG] Eventos que superan el umbral: {n_filtered}/{n_total} ({n_filtered/n_total*100:.1f}%)")
                    print(f"[DEBUG] Eventos descartados: {n_total - n_filtered}/{n_total} ({(n_total - n_filtered)/n_total*100:.1f}%)")
                else:
                    print("\n¬°Advertencia! Ning√∫n evento super√≥ el umbral de confianza.")
                    return
            
            # -------------------------------------------------------------------
            # 6.5.4. Mostrar estad√≠sticas de confianza
            # -------------------------------------------------------------------
            if len(filtered_confidence_scores) > 0:
                print("\nEstad√≠sticas de confianza (solo eventos clasificados):")
                print(f"  - M√≠nima: {np.min(filtered_confidence_scores):.4f}")
                print(f"  - M√°xima: {np.max(filtered_confidence_scores):.4f}")
                print(f"  - Media: {np.mean(filtered_confidence_scores):.4f}")
            else:
                print("\nNo hay eventos que cumplan con el umbral de confianza.")
                return
            
            # -------------------------------------------------------------------
            # 6.5.5. Validar conjunto de datos
            # -------------------------------------------------------------------
            if len(filtered_true_labels) == 0:
                print("\nNo quedan eventos v√°lidos despu√©s de aplicar el umbral de probabilidad.")
                return
            
            # Verificar el n√∫mero de clases √∫nicas
            unique_classes = set(filtered_true_labels)
            if len(unique_classes) < 2:
                # Si solo hay una clase, mostrar estad√≠sticas b√°sicas
                unique_label = list(unique_classes)[0]
                particle_name = LABEL_TO_PARTICLE.get(unique_label, 'Desconocida')
                total_events = len(filtered_true_labels)
                print(f"\n[DEBUG] total_events (filtered_true_labels) = {total_events}")
                correct_predictions = np.sum(filtered_true_labels == filtered_predicted_labels)
                accuracy = correct_predictions / total_events * 100
                
                print(f"\n¬°Advertencia! El dataset contiene solo una clase de part√≠cula: {particle_name}")
                print(f"Total de eventos: {total_events}")
                print(f"Predicciones correctas: {correct_predictions}")
                print(f"Precisi√≥n global: {accuracy:.2f}%")
                return
            
            # -------------------------------------------------------------------
            # 6.5.6. Calcular matriz de confusi√≥n sin filtrar
            # -------------------------------------------------------------------
            print("\nüîç Generando matriz de confusi√≥n sin filtrar...")
            # Usar las etiquetas originales sin filtrar
            predicted_unfiltered = np.argmax(probabilities, axis=1)
            cm_unfiltered = confusion_matrix(true_labels, predicted_unfiltered)
            
            # Calcular precisi√≥n global sin filtrar
            total_correct_unfiltered = np.sum(cm_unfiltered.diagonal())
            total_samples_unfiltered = np.sum(cm_unfiltered)
            accuracy_unfiltered = total_correct_unfiltered / total_samples_unfiltered if total_samples_unfiltered > 0 else 0
            
            # Mostrar resumen de precisi√≥n global sin filtrar
            print(f"Precisi√≥n global (sin filtrar): {accuracy_unfiltered:.4f} ({accuracy_unfiltered*100:.2f}%)")
            
            # Generar visualizaci√≥n de la matriz de confusi√≥n sin filtrar
            plt.figure(figsize=(8, 6))
            sns.heatmap(cm_unfiltered, annot=True, fmt='d', cmap='Blues',
                       xticklabels=['Electr√≥n', 'Positr√≥n', 'Gamma'],
                       yticklabels=['Electr√≥n', 'Positr√≥n', 'Gamma'])
            plt.title('Matriz de Confusi√≥n')
            plt.xlabel('Predicci√≥n')
            plt.ylabel('Valor Real')
            plt.savefig(f'{plots_dir}/matriz_confusion_sin_filtrar.png', dpi=300, bbox_inches='tight')
            plt.show()

            # -------------------------------------------------------------------
            # 6.5.7. An√°lisis de clasificaci√≥n por part√≠cula (sin filtrar)
            # -------------------------------------------------------------------
            print("\n" + "="*75)
            print("üìä AN√ÅLISIS DE CLASIFICACI√ìN POR PART√çCULA (SIN FILTRAR)".center(75))
            print("="*75)
            
            # Obtener predicciones sin filtrar
            predicted_unfiltered = np.argmax(probabilities, axis=1)
            
            # An√°lisis para cada tipo de part√≠cula (sin filtrar)
            for i, (label, particle) in enumerate(LABEL_TO_PARTICLE.items()):
                total_particles = np.sum(true_labels == i)
                if total_particles == 0:
                    print(f"\n‚ö†Ô∏è No hay eventos para la part√≠cula {particle}")
                    continue
                
                correct = cm_unfiltered[i, i]
                total_predicted = np.sum(predicted_unfiltered == i)
                accuracy = correct/total_particles*100 if total_particles > 0 else 0
                
                # Emoji para la part√≠cula
                emoji = {
                    'electr√≥n': 'üîµ',
                    'positr√≥n': 'üî¥',
                    'gamma': 'üü¢'
                }.get(particle.lower(), '‚Ä¢')
                
                # Barra de progreso para la precisi√≥n
                bar_length = 20
                filled_length = int(bar_length * correct / total_particles) if total_particles > 0 else 0
                bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
                
                print(f"\n{emoji} {particle.upper():<10} {'‚îÄ' * (75 - len(particle) - 2)}")
                print(f"   ‚Ä¢ Total eventos: {total_particles:>6}")
                print(f"   ‚Ä¢ Correctos:     {correct:>6} ({accuracy:5.1f}%) {bar}")
                
                # Mostrar errores de clasificaci√≥n si hay m√°s de una clase
                total_errors = np.sum(cm_unfiltered[i]) - correct if len(cm_unfiltered) > i else 0
                if len(LABEL_TO_PARTICLE) > 1 and total_errors > 0:
                    print(f"   ‚Ä¢ Errores:       {total_errors:>6} ({(100-accuracy):5.1f}%)")
                    print("     ‚îî‚îÄ" + "‚îÄ" * 68)
                    for j, (_, other_particle) in enumerate(LABEL_TO_PARTICLE.items()):
                        if i != j and i < len(cm_unfiltered) and j < len(cm_unfiltered[i]) and cm_unfiltered[i, j] > 0:
                            count = cm_unfiltered[i, j]
                            error_percentage = count / total_errors * 100 if total_errors > 0 else 0
                            error_bar = '‚îÇ' * (int(error_percentage/5) or 1)
                            print(f"       ‚Ä¢ Como {other_particle:<9}: {count:>6} ({error_percentage:5.1f}%) {error_bar}")
            
            print("\n" + "="*75 + "\n")
            
            
            # -------------------------------------------------------------------
            # 6.5.8. Calcular matriz de confusi√≥n filtrada
            # -------------------------------------------------------------------
            print("\nüîç Generando matriz de confusi√≥n con filtrado...")
            cm = confusion_matrix(filtered_true_labels, filtered_predicted_labels)
            
            # Calcular precisi√≥n global filtrada
            total_correct = np.sum(cm.diagonal()) if len(cm) > 0 else 0
            total_samples = np.sum(cm) if len(cm) > 0 else 0
            accuracy = total_correct / total_samples if total_samples > 0 else 0
            total_accuracy = total_correct / len(df)
            
            # Mostrar resumen de precisi√≥n global filtrada
            print(f"Precisi√≥n (filtrada): {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"Precisi√≥n global (filtrada): {total_accuracy:.4f} ({total_accuracy*100:.2f}%)")
            if prob_threshold > 0.0:
                print(f"Umbral de probabilidad aplicado: {prob_threshold*100:.0f}%")
                print(f"Eventos que superan el umbral: {len(filtered_true_labels)}/{len(true_labels)} ({(len(filtered_true_labels)/len(true_labels))*100:.1f}%)")
            
            # Generar visualizaci√≥n de la matriz de confusi√≥n filtrada
            plt.figure(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                       xticklabels=['Electr√≥n', 'Positr√≥n', 'Gamma'],
                       yticklabels=['Electr√≥n', 'Positr√≥n', 'Gamma'])
            plt.title('Matriz de Confusi√≥n (filtrada)')
            plt.xlabel('Predicci√≥n')
            plt.ylabel('Valor Real')
            plt.savefig(f'{plots_dir}/matriz_confusion_filtrada.png', dpi=300, bbox_inches='tight')
            plt.show()
    
            # -------------------------------------------------------------------
            # 6.5.9. An√°lisis de clasificaci√≥n por part√≠cula (filtrado)
            # -------------------------------------------------------------------
            print("\n" + "="*75)
            print("üìä AN√ÅLISIS DE CLASIFICACI√ìN POR PART√çCULA (FILTRADO)".center(75))
            print("="*75)
            
            # An√°lisis para cada tipo de part√≠cula (filtrado)
            for i, (label, particle) in enumerate(LABEL_TO_PARTICLE.items()):
                total_particles = np.sum(filtered_true_labels == i) if len(filtered_true_labels) > 0 else 0
                if total_particles == 0:
                    print(f"\n‚ö†Ô∏è No hay eventos para la part√≠cula {particle}")
                    continue
                
                correct = cm[i, i] if i < len(cm) and i < len(cm[i]) else 0
                total_predicted = np.sum(filtered_predicted_labels == i) if len(filtered_predicted_labels) > 0 else 0
                accuracy = correct/total_particles*100 if total_particles > 0 else 0
                
                # Emoji para la part√≠cula
                emoji = {
                    'electr√≥n': 'üîµ',
                    'positr√≥n': 'üî¥',
                    'gamma': 'üü¢'
                }.get(particle.lower(), '‚Ä¢')
                
                # Barra de progreso para la precisi√≥n
                bar_length = 20
                filled_length = int(bar_length * correct / total_particles) if total_particles > 0 else 0
                bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
                
                print(f"\n{emoji} {particle.upper():<10} {'‚îÄ' * (75 - len(particle) - 2)}")
                print(f"   ‚Ä¢ Total eventos: {total_particles:>6}")
                print(f"   ‚Ä¢ Correctos:     {correct:>6} ({accuracy:5.1f}%) {bar}")
                
                # Mostrar errores de clasificaci√≥n si hay m√°s de una clase
                total_errors = np.sum(cm[i]) - correct if i < len(cm) else 0
                if len(LABEL_TO_PARTICLE) > 1 and total_errors > 0:
                    print(f"   ‚Ä¢ Errores:       {total_errors:>6} ({(100-accuracy):5.1f}%)")
                    print("     ‚îî‚îÄ" + "‚îÄ" * 68)
                    for j, (_, other_particle) in enumerate(LABEL_TO_PARTICLE.items()):
                        if i != j and i < len(cm) and j < len(cm[i]) and cm[i, j] > 0:
                            count = cm[i, j]
                            error_percentage = count / total_errors * 100 if total_errors > 0 else 0
                            error_bar = '‚îÇ' * (int(error_percentage/5) or 1)
                            print(f"       ‚Ä¢ Como {other_particle:<9}: {count:>6} ({error_percentage:5.1f}%) {error_bar}")
            
            print("\n" + "="*75 + "\n")

            """
            # -------------------------------------------------------------------
            # 6.5.10. Histogramas de probabilidades de clasificaci√≥n (sin filtrar)
            # -------------------------------------------------------------------
            print("\nGenerando histogramas de probabilidades de clasificaci√≥n (datos sin filtrar)...")
            
            # Crear figura para los histogramas
            plt.figure(figsize=(15, 5))
            
            # Para cada tipo de part√≠cula (e-, e+, gamma)
            for i, (particle_name, color) in enumerate(zip(
                ['Electrones', 'Positrones', 'Gammas'],
                ['blue', 'red', 'green']
            )):
                plt.subplot(1, 3, i+1)
                mask = (true_labels == i)  # Usar all_true_labels sin filtrar
                
                if np.sum(mask) > 0:  # Si hay eventos de este tipo
                    # Graficar histograma de las probabilidades de la clase correcta
                    probs = probabilities[mask, i]  # Usar probabilities sin filtrar
                    plt.hist(probs, 
                            bins=20, 
                            alpha=0.7, 
                            color=color,
                            edgecolor='black')
                    plt.title(f'{particle_name} reales (n={np.sum(mask)})')
                    plt.xlabel(f'Prob. de ser {particle_name.lower().rstrip("s")}')
                    plt.ylabel('N√∫mero de eventos')
                    plt.xlim(0, 1)
                    plt.grid(True, alpha=0.3)
                else:
                    plt.text(0.5, 0.5, f'No hay {particle_name.lower()} reales', 
                            ha='center', va='center')
                    plt.xlim(0, 1)
                    plt.ylim(0, 1)
            
            plt.tight_layout()
            plt.suptitle(f'Distribuci√≥n de probabilidades (sin filtrar, {len(true_labels)} eventos)', y=1.05)
            # Guardar la figura
            plt.savefig(f'{plots_dir}/histogramas_probabilidades_sin_filtrar.png', dpi=300, bbox_inches='tight')
            plt.show()  # Mostrar la figura de los histogramas
            """
            # -------------------------------------------------------------------
            # 6.5.10 Histogramas de probabilidades detallados por clase real y predicha (sin filtrar)
            # -------------------------------------------------------------------
            
            print("\nGenerando histogramas detallados de probabilidades por clase real y predicha (sin filtrar)...")
            
            # Nombres de las part√≠culas para los t√≠tulos
            particle_names = ['Electrones', 'Positrones', 'Gammas']
            particle_short = ['e-', 'e+', 'Œ≥']
            particle_root = ['electron', 'positron', 'gamma']  # Nombres para los histogramas ROOT
            colors = ['blue', 'red', 'green']
            
            # Lista para guardar los histogramas de ROOT
            root_histos = []
            
            # Crear una figura grande para todos los histogramas
            plt.figure(figsize=(20, 15))
            
            # √çndice para el subplot
            plot_idx = 1
            
            # Para cada tipo de part√≠cula REAL (filas)
            for true_idx, (true_name, true_short) in enumerate(zip(particle_names, particle_short)):
                # Para cada tipo de part√≠cula PREDICHA (columnas)
                for pred_idx, (pred_name, pred_short, color) in enumerate(zip(particle_names, particle_short, colors)):
                    plt.subplot(3, 3, plot_idx)
                    
                    # Obtener m√°scara para la part√≠cula real actual
                    mask = (true_labels == true_idx)
                    
                    if np.sum(mask) > 0:  # Si hay eventos de este tipo
                        # Obtener probabilidades para la clase predicha actual
                        probs = probabilities[mask, pred_idx]
                        
                        # Crear histograma de matplotlib
                        n, bins, _ = plt.hist(probs, 
                                        bins=20, 
                                        alpha=0.7, 
                                        color=color,
                                        edgecolor='black')  # Mostrar n√∫mero de eventos absolutos
                                        
                        # Crear histograma de ROOT con estilo de solo barras
                        hist_name = f'h_prob_{particle_root[true_idx]}_as_{particle_root[pred_idx]}'
                        hist_title = f'{particle_root[true_idx]} as {particle_root[pred_idx]};Probability;Counts'
                        nbins = 20
                        xmin, xmax = 0.0, 1.0
                        
                        # Crear y configurar histograma
                        root_hist = ROOT.TH1F(hist_name, hist_title, nbins, xmin, xmax)
                        root_hist.SetStats(0)  # Desactivar caja de estad√≠sticas
                        root_hist.SetLineColor(ROOT.kBlack)
                        root_hist.SetLineWidth(1)
                        root_hist.SetFillColor(ROOT.kBlue)  # Color de relleno
                        root_hist.SetFillStyle(1001)  # Relleno s√≥lido
                        
                        # Llenar el histograma
                        for prob in probs:
                            root_hist.Fill(prob)
                        
                        # A√±adir a la lista de histogramas
                        root_histos.append(root_hist)
                        
                        # Configurar t√≠tulo y etiquetas
                        plt.title(f'Reales: {true_name}\nPredichos como: {pred_name}')
                        plt.xlabel(f'Prob. de ser {pred_short}')
                        plt.ylabel('N√∫mero de eventos')
                        plt.xlim(0, 1)
                        plt.grid(True, alpha=0.3)
                        
                        # A√±adir el n√∫mero de eventos en la esquina superior derecha
                        plt.text(0.98, 0.95, f'N = {np.sum(mask):,}', 
                                transform=plt.gca().transAxes,
                                ha='right', va='top',
                                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))
                    else:
                        plt.text(0.5, 0.5, f'No hay {true_name.lower()} reales', 
                                ha='center', va='center')
                        plt.xlim(0, 1)
                        plt.ylim(0, 1)
                    
                    # Incrementar el √≠ndice del subplot
                    plot_idx += 1
            
            # Ajustar el dise√±o y guardar la figura
            plt.tight_layout()
            plt.suptitle(f'Distribuciones de probabilidad por clase real y predicha\n(Total eventos: {len(true_labels):,})', y=1.02, fontsize=14)
            plt.savefig(f'{plots_dir}/histogramas_probabilidades_detallados.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("Histogramas detallados guardados en:", f'{plots_dir}/histogramas_probabilidades_detallados.png')
            
            # Guardar los histogramas en el archivo ROOT
            try:
                # Obtener el nombre del archivo ROOT de entrada
                if hasattr(file, '_file') and hasattr(file._file, 'fFilePath'):
                    root_file_path = file._file.fFilePath
                else:
                    root_file_path = input_file
                
                # Abrir el archivo ROOT en modo actualizaci√≥n
                root_file = ROOT.TFile(root_file_path, 'UPDATE')
                
                # Crear o acceder al directorio prob_histo
                root_dir = root_file.GetDirectory('prob_histo')
                if not root_dir:
                    root_dir = root_file.mkdir('prob_histo')
                root_dir.cd()
                
                # Guardar cada histograma
                for hist in root_histos:
                    hist.Write(hist.GetName(), ROOT.TObject.kOverwrite)
                
                # Cerrar el archivo
                root_file.Close()
                print(f"\nHistogramas guardados en el archivo ROOT: {root_file_path}:/prob_histo/")
                
            except Exception as e:
                print(f"\n‚ö†Ô∏è  Error al guardar los histogramas en el archivo ROOT: {e}")
                print("Los histogramas se han guardado correctamente en formato PNG, pero no en el archivo ROOT.")
            
            """
            # -------------------------------------------------------------------
            # 6.5.11. Histogramas de probabilidades de clasificaci√≥n (filtrados por umbral)
            # -------------------------------------------------------------------
            print("\nGenerando histogramas de probabilidades de clasificaci√≥n (datos filtrados)...")
            
            # Crear figura para los histogramas
            plt.figure(figsize=(15, 5))
            
            # Para cada tipo de part√≠cula (e-, e+, gamma)
            for i, (particle_name, color) in enumerate(zip(
                ['Electrones', 'Positrones', 'Gammas'],
                ['blue', 'red', 'green']
            )):
                plt.subplot(1, 3, i+1)
                mask = (filtered_true_labels == i)  # Usar filtered_true_labels
                
                if np.sum(mask) > 0:  # Si hay eventos de este tipo
                    # Graficar histograma de las probabilidades de la clase correcta
                    probs = filtered_probabilities[mask, i]  # Usar filtered_probabilities
                    plt.hist(probs, 
                            bins=20, 
                            alpha=0.7, 
                            color=color,
                            edgecolor='black')
                    plt.title(f'{particle_name} reales (n={np.sum(mask)})')
                    plt.xlabel(f'Prob. de ser {particle_name.lower().rstrip("s")}')
                    plt.ylabel('N√∫mero de eventos')
                    plt.xlim(0, 1)
                    plt.grid(True, alpha=0.3)
                else:
                    plt.text(0.5, 0.5, f'No hay {particle_name.lower()} reales', 
                            ha='center', va='center')
                    plt.xlim(0, 1)
                    plt.ylim(0, 1)
            
            plt.tight_layout()
            plt.suptitle(f'Distribuci√≥n de probabilidades (filtrado, {len(filtered_true_labels)} eventos)', y=1.05)
            plt.savefig(f'{plots_dir}/histogramas_probabilidades_filtrados.png', dpi=300, bbox_inches='tight')
            plt.show()  # Mostrar la figura de los histogramas
            """
            # -------------------------------------------------------------------
            # 6.5.11. Histogramas de probabilidades detallados por clase real y predicha (filtrados)
            # -------------------------------------------------------------------
            
            print("\nGenerando histogramas detallados de probabilidades por clase real y predicha (filtrados)...")
            
            # Lista para guardar los histogramas de ROOT filtrados
            root_histos_filtered = []
            
            # Crear una figura grande para todos los histogramas
            plt.figure(figsize=(20, 15))
            
            # √çndice para el subplot
            plot_idx = 1
            
            # Para cada tipo de part√≠cula REAL (filas)
            for true_idx, (true_name, true_short) in enumerate(zip(particle_names, particle_short)):
                # Para cada tipo de part√≠cula PREDICHA (columnas)
                for pred_idx, (pred_name, pred_short, color) in enumerate(zip(particle_names, particle_short, colors)):
                    plt.subplot(3, 3, plot_idx)
                    
                    # Obtener m√°scara para la part√≠cula real actual en los datos filtrados
                    mask = (filtered_true_labels == true_idx)
                    
                    if np.sum(mask) > 0:  # Si hay eventos de este tipo
                        # Obtener probabilidades para la clase predicha actual
                        probs = filtered_probabilities[mask, pred_idx]
                        
                        # Crear histograma de matplotlib
                        n, bins, _ = plt.hist(probs, 
                                        bins=20, 
                                        alpha=0.7, 
                                        color=color,
                                        edgecolor='black')  # Mostrar n√∫mero de eventos absolutos
                                                
                        # Crear histograma de ROOT con estilo de solo barras
                        hist_name = f'h_prob_{particle_root[true_idx]}_as_{particle_root[pred_idx]}_filtered'
                        hist_title = f'{particle_root[true_idx]} as {particle_root[pred_idx]} (filtered);Probability;Counts'
                        nbins = 20
                        xmin, xmax = 0.0, 1.0
                        
                        # Crear y configurar histograma
                        root_hist = ROOT.TH1F(hist_name, hist_title, nbins, xmin, xmax)
                        root_hist.SetStats(0)  # Desactivar caja de estad√≠sticas
                        root_hist.SetLineColor(ROOT.kBlack)
                        root_hist.SetLineWidth(1)
                        root_hist.SetFillColor(ROOT.kBlue)  # Color de relleno
                        root_hist.SetFillStyle(1001)  # Relleno s√≥lido
                        
                        # Llenar el histograma
                        for prob in probs:
                            root_hist.Fill(prob)
                        
                        # A√±adir a la lista de histogramas
                        root_histos_filtered.append(root_hist)
                        
                        # Configurar t√≠tulo y etiquetas
                        plt.title(f'Reales: {true_name}\nPredichos como: {pred_name}\n(Eventos filtrados)')
                        plt.xlabel(f'Prob. de ser {pred_short}')
                        plt.ylabel('N√∫mero de eventos')
                        plt.xlim(0, 1)
                        plt.grid(True, alpha=0.3)
                        
                        # A√±adir el n√∫mero de eventos en la esquina superior derecha
                        plt.text(0.98, 0.95, f'N = {np.sum(mask):,}', 
                                transform=plt.gca().transAxes,
                                ha='right', va='top',
                                bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))
                    else:
                        plt.text(0.5, 0.5, f'No hay {true_name.lower()} reales\n(filtrados)', 
                                ha='center', va='center')
                        plt.xlim(0, 1)
                        plt.ylim(0, 1)
                    
                    # Incrementar el √≠ndice del subplot
                    plot_idx += 1
            
            # Ajustar el dise√±o y guardar la figura
            plt.tight_layout()
            plt.suptitle(f'Distribuciones de probabilidad por clase real y predicha\n(Eventos filtrados, {len(filtered_true_labels):,} eventos)', y=1.02, fontsize=14)
            plt.savefig(f'{plots_dir}/histogramas_probabilidades_detallados_filtrados.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("Histogramas detallados (filtrados) guardados en:", f'{plots_dir}/histogramas_probabilidades_detallados_filtrados.png')
            
            # Guardar los histogramas en el archivo ROOT
            try:
                # Obtener el nombre del archivo ROOT de entrada
                if hasattr(file, '_file') and hasattr(file._file, 'fFilePath'):
                    root_file_path = file._file.fFilePath
                else:
                    root_file_path = input_file
                
                # Abrir el archivo ROOT en modo actualizaci√≥n
                root_file = ROOT.TFile(root_file_path, 'UPDATE')
                
                # Crear o acceder al directorio prob_histo_filtered
                root_dir = root_file.GetDirectory('prob_histo_filtered')
                if not root_dir:
                    root_dir = root_file.mkdir('prob_histo_filtered')
                root_dir.cd()
                
                # Guardar cada histograma filtrado
                for hist in root_histos_filtered:
                    hist.Write(hist.GetName(), ROOT.TObject.kOverwrite)
                
                # Cerrar el archivo
                root_file.Close()
                print(f"\nHistogramas filtrados guardados en el archivo ROOT: {root_file_path}:/prob_histo_filtered/")
                
            except Exception as e:
                print(f"\n‚ö†Ô∏è  Error al guardar los histogramas filtrados en el archivo ROOT: {e}")
                print("Los histogramas filtrados se han guardado correctamente en formato PNG, pero no en el archivo ROOT.")
            
            # -------------------------------------------------------------------
            # 6.5.12.1 Curva ROC para positrones vs gammas
            # -------------------------------------------------------------------
            
            print("\nGenerando curva ROC para positrones vs gammas...")
            
            # Obtener m√°scaras para positrones reales
            true_positrons = (true_labels == 1)  # √çndice 1 para positrones
            
            # Obtener probabilidades de ser positrones y gammas para todos los eventos
            probs_positron = probabilities[:, 1]  # Probabilidad de ser positr√≥n
            probs_gamma = probabilities[:, 2]      # Probabilidad de ser gamma
            
            # Umbrales para la curva ROC (de 0 a 1 con pasos de 0.01)
            thresholds = np.linspace(0, 1, 101)
            
            # Arrays para almacenar TPR y FPR
            tpr = []  # True Positive Rate
            fpr = []  # False Positive Rate
            
            for thresh in thresholds:
                # Predicci√≥n de positr√≥n (positivo) cuando la probabilidad > umbral
                pred_positron = probs_positron > thresh
                
                # Calcular TPR: VP / (VP + FN)
                vp = np.sum(true_positrons & pred_positron)
                fn = np.sum(true_positrons & ~pred_positron)
                tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                
                # Calcular FPR: FP / (FP + TN)
                true_gammas = (true_labels == 2)  # √çndice 2 para gammas
                fp = np.sum(true_gammas & pred_positron)
                tn = np.sum(true_gammas & ~pred_positron)
                fpr_val = fp / (fp + tn) if (fp + tn) > 0 else 0
                
                tpr.append(tpr_val)
                fpr.append(fpr_val)
                
                # Mostrar TPR y FPR para umbrales 0.1, 0.2, ..., 0.9
                if round(thresh*10) == thresh*10 and 0 < thresh < 1.0:
                    print(f"Umbral {thresh:.1f}: TPR = {tpr_val:.4f}, FPR = {fpr_val:.4f}")
            
            # Convertir a arrays de numpy
            tpr = np.array(tpr)
            fpr = np.array(fpr)
            
            # Encontrar puntos donde TPR est√° m√°s cercano a 0.5 y 0.8
            idx_05 = np.argmin(np.abs(tpr - 0.5))
            idx_08 = np.argmin(np.abs(tpr - 0.8))
            fpr_at_tpr_05 = fpr[idx_05]
            fpr_at_tpr_08 = fpr[idx_08]
            print(f"\n[Positrones vs Gammas]")
            print(f"Cuando TPR ‚âà 0.5, FPR = {fpr_at_tpr_05:.4f}")
            print(f"Cuando TPR ‚âà 0.8, FPR = {fpr_at_tpr_08:.4f}")
            
            # Calcular el √°rea bajo la curva ROC (AUC)
            # Las m√©tricas ya est√°n importadas al inicio del archivo
            roc_auc = auc(fpr, tpr)
            
            # Crear la figura
            plt.figure(figsize=(10, 8))
            plt.semilogy(tpr, fpr, color='darkorange', lw=2, 
                        label=f'Curva ROC (AUC = {roc_auc:.3f})')
            plt.xlim([0.5, 1.0])  # Rango del eje X ajustado a [0.5, 1.0]
            plt.ylim([1e-4, 1.05])  # L√≠mite inferior peque√±o pero no cero para escala log
            plt.xlabel('TPR (True Positive Rate)')
            plt.ylabel('FPR (False Positive Rate, escala log)')
            plt.title('Curva ROC: Positrones vs Gammas')
            plt.legend(loc="lower right")
            plt.grid(True, which="both", alpha=0.3)
            
            # Guardar la figura
            plt.savefig(f'{plots_dir}/roc_curve_positron_vs_gamma.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("Curva ROC guardada en:", f'{plots_dir}/roc_curve_positron_vs_gamma.png')
            
            # -------------------------------------------------------------------
            # 6.5.12.2 Curva ROC para Gammas vs Electrones
            # -------------------------------------------------------------------
            
            print("\nGenerando curva ROC para gammas vs electrones...")
            
            # Obtener m√°scaras para gammas reales
            true_gammas = (true_labels == 2)  # √çndice 2 para gammas
            
            # Obtener probabilidades de ser gammas y electrones para todos los eventos
            probs_gamma = probabilities[:, 2]     # Probabilidad de ser gamma
            probs_electron = probabilities[:, 0]   # Probabilidad de ser electr√≥n
            
            # Umbrales para la curva ROC (de 0 a 1 con pasos de 0.01)
            thresholds = np.linspace(0, 1, 101)
            
            # Arrays para almacenar TPR y FPR
            tpr_g = []  # True Positive Rate para gammas
            fpr_g = []  # False Positive Rate (clasificar electrones como gammas)
            
            for thresh in thresholds:
                # Predicci√≥n de gamma (positivo) cuando la probabilidad > umbral
                pred_gamma = probs_gamma > thresh
                
                # Calcular TPR: VP / (VP + FN)
                vp = np.sum(true_gammas & pred_gamma)
                fn = np.sum(true_gammas & ~pred_gamma)
                tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                
                # Calcular FPR: FP / (FP + TN)
                true_electrons = (true_labels == 0)  # √çndice 0 para electrones
                fp = np.sum(true_electrons & pred_gamma)
                tn = np.sum(true_electrons & ~pred_gamma)
                fpr_val = fp / (fp + tn) if (fp + tn) > 0 else 0
                
                tpr_g.append(tpr_val)
                fpr_g.append(fpr_val)
            
            # Convertir a arrays de numpy
            tpr_g = np.array(tpr_g)
            fpr_g = np.array(fpr_g)
            
            # Calcular el √°rea bajo la curva ROC (AUC)
            roc_auc_g = auc(fpr_g, tpr_g)
            
            # Crear la figura
            plt.figure(figsize=(10, 8))
            plt.semilogy(tpr_g, fpr_g, color='green', lw=2, 
                        label=f'Curva ROC (AUC = {roc_auc_g:.3f})')
            plt.xlim([0.5, 1.0])  # Mismo rango que para positrones
            plt.ylim([1e-4, 1.05])
            plt.xlabel('TPR (True Positive Rate)')
            plt.ylabel('FPR (False Positive Rate, escala log)')
            plt.title('Curva ROC: Gammas vs Electrones')
            plt.legend(loc="lower right")
            plt.grid(True, which="both", alpha=0.3)
            
            # Guardar la figura
            plt.savefig(f'{plots_dir}/roc_curve_gamma_vs_electron.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("Curva ROC guardada en:", f'{plots_dir}/roc_curve_gamma_vs_electron.png')
            
            # -------------------------------------------------------------------
            # 6.5.12.3 Curva ROC para Electrones vs Gammas
            # -------------------------------------------------------------------
            
            print("\nGenerando curva ROC para electrones vs gammas...")
            
            # Obtener m√°scaras para electrones reales
            true_electrons = (true_labels == 0)  # √çndice 0 para electrones
            
            # Obtener probabilidades de ser electrones y gammas para todos los eventos
            probs_electron = probabilities[:, 0]  # Probabilidad de ser electr√≥n
            probs_gamma = probabilities[:, 2]     # Probabilidad de ser gamma
            
            # Umbrales para la curva ROC (de 0 a 1 con pasos de 0.01)
            thresholds = np.linspace(0, 1, 101)
            
            # Arrays para almacenar TPR y FPR
            tpr_e = []  # True Positive Rate para electrones
            fpr_e = []  # False Positive Rate (clasificar gammas como electrones)
            
            for thresh in thresholds:
                # Predicci√≥n de electr√≥n (positivo) cuando la probabilidad > umbral
                pred_electron = probs_electron > thresh
                
                # Calcular TPR: VP / (VP + FN)
                vp = np.sum(true_electrons & pred_electron)
                fn = np.sum(true_electrons & ~pred_electron)
                tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                
                # Calcular FPR: FP / (FP + TN)
                true_gammas = (true_labels == 2)  # √çndice 2 para gammas
                fp = np.sum(true_gammas & pred_electron)    # Gammas mal clasificados como electrones
                tn = np.sum(true_gammas & ~pred_electron)   # Gammas correctamente identificados
                fpr_val = fp / (fp + tn) if (fp + tn) > 0 else 0
                
                tpr_e.append(tpr_val)
                fpr_e.append(fpr_val)
            
            # Convertir a arrays de numpy
            tpr_e = np.array(tpr_e)
            fpr_e = np.array(fpr_e)
            
            # Calcular el √°rea bajo la curva ROC (AUC)
            roc_auc_e = auc(fpr_e, tpr_e)
            
            # Crear la figura
            plt.figure(figsize=(10, 8))
            plt.semilogy(tpr_e, fpr_e, color='blue', lw=2, 
                        label=f'Curva ROC (AUC = {roc_auc_e:.3f})')
            plt.xlim([0.5, 1.0])  # Mismo rango que para las otras curvas
            plt.ylim([1e-4, 1.05])  # L√≠mite inferior peque√±o pero no cero para escala log
            plt.xlabel('TPR (True Positive Rate)')
            plt.ylabel('FPR (False Positive Rate, escala log)')
            plt.title('Curva ROC: Electrones vs Gammas')
            plt.legend(loc="lower right")
            plt.grid(True, which="both", alpha=0.3)
            
            # Guardar la figura
            plt.savefig(f'{plots_dir}/roc_curve_electron_vs_gamma.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("Curva ROC guardada en:", f'{plots_dir}/roc_curve_electron_vs_gamma.png')
            
            # -------------------------------------------------------------------
            # 6.5.12.2 Curva ROC: Electrones vs Positrones
            # -------------------------------------------------------------------
            print("\nGenerando curva ROC para electrones vs positrones...")
            
            # Obtener m√°scaras para electrones y positrones reales
            true_electrons = (true_labels == 0)  # √çndice 0 para electrones
            true_positrons = (true_labels == 1)  # √çndice 1 para positrones
            
            # Obtener probabilidades de ser electrones para todos los eventos
            probs_electron = probabilities[:, 0]  # Probabilidad de ser electr√≥n
            
            # Umbrales para la curva ROC (de 0 a 1 con pasos de 0.01)
            thresholds = np.linspace(0, 1, 101)
            
            # Arrays para almacenar TPR y FPR
            tpr_e_pos = []  # True Positive Rate para electrones
            fpr_e_pos = []  # False Positive Rate (clasificar positrones como electrones)
            
            for thresh in thresholds:
                # Predicci√≥n de electr√≥n (positivo) cuando la probabilidad > umbral
                pred_electron = probs_electron > thresh
                
                # Calcular TPR: VP / (VP + FN) para electrones
                vp = np.sum(true_electrons & pred_electron)
                fn = np.sum(true_electrons & ~pred_electron)
                tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                
                # Calcular FPR: FP / (FP + TN) para positrones
                fp = np.sum(true_positrons & pred_electron)    # Positrones mal clasificados como electrones
                tn = np.sum(true_positrons & ~pred_electron)   # Positrones correctamente identificados
                fpr_val = fp / (fp + tn) if (fp + tn) > 0 else 0
                
                tpr_e_pos.append(tpr_val)
                fpr_e_pos.append(fpr_val)
            
            # Convertir a arrays de numpy
            tpr_e_pos = np.array(tpr_e_pos)
            fpr_e_pos = np.array(fpr_e_pos)
            
            # Calcular el √°rea bajo la curva ROC (AUC)
            roc_auc_e_pos = auc(fpr_e_pos, tpr_e_pos)
            
            # Crear la figura
            plt.figure(figsize=(10, 8))
            plt.semilogy(tpr_e_pos, fpr_e_pos, color='green', lw=2, 
                        label=f'Curva ROC (AUC = {roc_auc_e_pos:.3f})')
            plt.xlim([0.5, 1.0])  # Mismo rango que para las otras curvas
            plt.ylim([1e-4, 1.05])  # L√≠mite inferior peque√±o pero no cero para escala log
            plt.xlabel('TPR (True Positive Rate)')
            plt.ylabel('FPR (False Positive Rate, escala log)')
            plt.title('Curva ROC: Electrones vs Positrones')
            plt.legend(loc="lower right")
            plt.grid(True, which="both", alpha=0.3)
            
            # Guardar la figura
            plt.savefig(f'{plots_dir}/roc_curve_electron_vs_positron.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("Curva ROC guardada en:", f'{plots_dir}/roc_curve_electron_vs_positron.png')
            
            # -------------------------------------------------------------------
            # 6.5.12.3 Curva ROC: Positrones vs Electrones
            # -------------------------------------------------------------------
            print("\nGenerando curva ROC para positrones vs electrones...")
            
            # Obtener m√°scaras para positrones y electrones reales
            true_positrons = (true_labels == 1)  # √çndice 1 para positrones
            true_electrons = (true_labels == 0)  # √çndice 0 para electrones
            
            # Obtener probabilidades de ser positrones para todos los eventos
            probs_positron = probabilities[:, 1]  # Probabilidad de ser positr√≥n
            
            # Umbrales para la curva ROC (de 0 a 1 con pasos de 0.01)
            thresholds = np.linspace(0, 1, 101)
            
            # Arrays para almacenar TPR y FPR
            tpr_pos_e = []  # True Positive Rate para positrones
            fpr_pos_e = []  # False Positive Rate (clasificar electrones como positrones)
            
            for thresh in thresholds:
                # Predicci√≥n de positr√≥n (positivo) cuando la probabilidad > umbral
                pred_positron = probs_positron > thresh
                
                # Calcular TPR: VP / (VP + FN) para positrones
                vp = np.sum(true_positrons & pred_positron)
                fn = np.sum(true_positrons & ~pred_positron)
                tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                
                # Calcular FPR: FP / (FP + TN) para electrones
                fp = np.sum(true_electrons & pred_positron)    # Electrones mal clasificados como positrones
                tn = np.sum(true_electrons & ~pred_positron)   # Electrones correctamente identificados
                fpr_val = fp / (fp + tn) if (fp + tn) > 0 else 0
                
                tpr_pos_e.append(tpr_val)
                fpr_pos_e.append(fpr_val)

                # Mostrar TPR y FPR para umbrales 0.1, 0.2, ..., 0.9
                if round(thresh*10) == thresh*10 and 0 < thresh < 1.0:
                    print(f"Umbral {thresh:.1f}: TPR = {tpr_val:.4f}, FPR = {fpr_val:.4f}")
            
            # Convertir a arrays de numpy
            tpr_pos_e = np.array(tpr_pos_e)
            fpr_pos_e = np.array(fpr_pos_e)
            
            # Encontrar puntos donde TPR est√° m√°s cercano a 0.5 y 0.8
            idx_05 = np.argmin(np.abs(tpr_pos_e - 0.5))
            idx_08 = np.argmin(np.abs(tpr_pos_e - 0.8))
            fpr_at_tpr_05 = fpr_pos_e[idx_05]
            fpr_at_tpr_08 = fpr_pos_e[idx_08]
            print(f"\n[Positrones vs Electrones]")
            print(f"Cuando TPR ‚âà 0.5, FPR = {fpr_at_tpr_05:.4f}")
            print(f"Cuando TPR ‚âà 0.8, FPR = {fpr_at_tpr_08:.4f}")
            
            # Calcular el √°rea bajo la curva ROC (AUC)
            roc_auc_pos_e = auc(fpr_pos_e, tpr_pos_e)
            
            # Crear la figura
            plt.figure(figsize=(10, 8))
            plt.semilogy(tpr_pos_e, fpr_pos_e, color='purple', lw=2, 
                        label=f'Curva ROC (AUC = {roc_auc_pos_e:.3f})')
            plt.xlim([0.5, 1.0])  # Mismo rango que para las otras curvas
            plt.ylim([1e-4, 1.05])  # L√≠mite inferior peque√±o pero no cero para escala log
            plt.xlabel('TPR (True Positive Rate)')
            plt.ylabel('FPR (False Positive Rate, escala log)')
            plt.title('Curva ROC: Positrones vs Electrones')
            plt.legend(loc="lower right")
            plt.grid(True, which="both", alpha=0.3)
            
            # Guardar la figura
            plt.savefig(f'{plots_dir}/roc_curve_positron_vs_electron.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("Curva ROC guardada en:", f'{plots_dir}/roc_curve_positron_vs_electron.png')
            
            
            # -------------------------------------------------------------------
            # 6.5.12.4 An√°lisis de umbrales para e+ vs Œ≥ y e+ vs e- (ALGORITMO EN PRUEBAS)
            # -------------------------------------------------------------------
            print("\nüîç Analizando umbrales para clasificaci√≥n de positrones...")
            
            # Obtener probabilidades de ser positr√≥n y ser gamma
            probs_positron = probabilities[:, 1]  # Probabilidad de ser e+
            probs_gamma = probabilities[:, 2]     # Probabilidad de ser gamma
            
            # Umbrales a evaluar
            thresholds = np.linspace(0.1, 0.9, 9)
            
            # Resultados
            print("\nUmbral | TPR (e+ vs Œ≥) | FPR (e+ vs Œ≥) | TPR (e+ vs e-) | FPR (e+ vs e-)")
            print("-" * 75)
            
            for thresh in thresholds:
                # Clasificaci√≥n de positrones vs gamma
                pred_positron_vs_gamma = (probs_positron >= thresh)
                
                # Calcular m√©tricas para e+ vs Œ≥
                tp_gamma = np.sum(true_positrons & pred_positron_vs_gamma)
                fn_gamma = np.sum(true_positrons & ~pred_positron_vs_gamma)
                fp_gamma = np.sum((true_labels == 2) & pred_positron_vs_gamma)
                tn_gamma = np.sum((true_labels == 2) & ~pred_positron_vs_gamma)
                
                tpr_vs_gamma = tp_gamma / (tp_gamma + fn_gamma) if (tp_gamma + fn_gamma) > 0 else 0
                fpr_vs_gamma = fp_gamma / (fp_gamma + tn_gamma) if (fp_gamma + tn_gamma) > 0 else 0
                
                # Calcular m√©tricas para e+ vs e-
                fp_eminus = np.sum((true_labels == 0) & pred_positron_vs_gamma)
                tn_eminus = np.sum((true_labels == 0) & ~pred_positron_vs_gamma)
                fpr_vs_eminus = fp_eminus / (fp_eminus + tn_eminus) if (fp_eminus + tn_eminus) > 0 else 0
                
                # Imprimir resultados
                print(f"{thresh:.2f}   | {tpr_vs_gamma:^12.3f}  | {fpr_vs_gamma:^12.3f}  | {tpr_vs_gamma:^12.3f}  | {fpr_vs_eminus:^12.3f}")
            
            # Guardar resultados en un archivo
            threshold_file = f'{plots_dir}/umbrales_positrones.txt'
            with open(threshold_file, 'w') as f:
                f.write("An√°lisis de umbrales para clasificaci√≥n de positrones\n")
                f.write("="*60 + "\n\n")
                f.write("Umbral | TPR (e+ vs Œ≥) | FPR (e+ vs Œ≥) | TPR (e+ vs e-) | FPR (e+ vs e-)\n")
                f.write("-"*75 + "\n")
                
                for thresh in thresholds:
                    pred_positron_vs_gamma = (probs_positron >= thresh)
                    
                    # M√©tricas para e+ vs Œ≥
                    tp_gamma = np.sum(true_positrons & pred_positron_vs_gamma)
                    fn_gamma = np.sum(true_positrons & ~pred_positron_vs_gamma)
                    fp_gamma = np.sum((true_labels == 2) & pred_positron_vs_gamma)
                    tn_gamma = np.sum((true_labels == 2) & ~pred_positron_vs_gamma)
                    
                    tpr_vs_gamma = tp_gamma / (tp_gamma + fn_gamma) if (tp_gamma + fn_gamma) > 0 else 0
                    fpr_vs_gamma = fp_gamma / (fp_gamma + tn_gamma) if (fp_gamma + tn_gamma) > 0 else 0
                    
                    # M√©tricas para e+ vs e-
                    fp_eminus = np.sum((true_labels == 0) & pred_positron_vs_gamma)
                    tn_eminus = np.sum((true_labels == 0) & ~pred_positron_vs_gamma)
                    fpr_vs_eminus = fp_eminus / (fp_eminus + tn_eminus) if (fp_eminus + tn_eminus) > 0 else 0
                    
                    f.write(f"{thresh:.2f}   | {tpr_vs_gamma:^12.3f}  | {fpr_vs_gamma:^12.3f}  | {tpr_vs_gamma:^12.3f}  | {fpr_vs_eminus:^12.3f}\n")
            
            print(f"\nüìÑ Resultados detallados guardados en: {threshold_file}")

            # -------------------------------------------------------------------
            # 6.5.13. Mapas de calor
            # -------------------------------------------------------------------
            bins = 20
            range_ = [[0, 1], [0, 1]]

            # Crear m√°scaras para cada tipo de part√≠cula real (usando datos filtrados)
            is_electron = (filtered_true_labels == 0)
            is_positron = (filtered_true_labels == 1)
            is_gamma = (filtered_true_labels == 2)
            
            # Crear una nueva figura para los mapas de calor
            plt.figure(figsize=(15, 6))
            fig_heatmap = plt.gcf()  # Obtener la figura actual
            
            # -------------------------------------------------------------------
            # 6.5.13.1 Mapa de calor: Probabilidades para positrones reales
            # -------------------------------------------------------------------
            
            plt.subplot(1, 2, 1)
            if np.any(is_positron):
                plt.hist2d(filtered_probabilities[is_positron, 1],  # Prob. de ser e+
                           filtered_probabilities[is_positron, 2],  # Prob. de ser gamma
                           bins=bins, range=range_, 
                           cmap='Reds', norm=LogNorm())
                plt.colorbar(label='N√∫mero de eventos')
                plt.title('e+ reales')
                plt.xlabel('Prob. de ser e+')
                plt.ylabel('Prob. de ser gamma')
            else:
                plt.text(0.5, 0.5, 'No hay e+ reales', 
                         ha='center', va='center')
            
            # -------------------------------------------------------------------
            # 6.5.13.2 Mapa de calor: Probabilidades para gammas reales
            # -------------------------------------------------------------------
            plt.subplot(1, 2, 2)
            if np.any(is_gamma):
                plt.hist2d(filtered_probabilities[is_gamma, 1],  # Prob. de ser e+
                          filtered_probabilities[is_gamma, 2],    # Prob. de ser gamma
                          bins=bins, range=range_,
                          cmap='Blues', norm=LogNorm())
                plt.colorbar(label='N√∫mero de eventos')
                plt.title('Gammas reales')
                plt.xlabel('Prob. de ser e+')
                plt.ylabel('Prob. de ser gamma')
            else:
                plt.text(0.5, 0.5, 'No hay gammas reales',
                         ha='center', va='center')
            
            # Ajustar el dise√±o de la figura
            plt.tight_layout()
            
            # Guardar la figura de los mapas de calor
            output_file = f'{plots_dir}/mapas_calor.png'
            fig_heatmap.savefig(output_file, dpi=300, bbox_inches='tight')
            print(f'   - Gr√°fico guardado: {output_file}')
            plt.show()
            
            # ===================================================================
            # 6.6. AN√ÅLISIS POR ENERG√çA CIN√âTICA
            # ===================================================================
            print("\n‚ö° Analizando rendimiento por energ√≠a cin√©tica...")
            
            # -------------------------------------------------------------------
            # 6.6.1. Validaci√≥n y preparaci√≥n de datos
            # -------------------------------------------------------------------
            print("   - Validando y preparando datos...")
            
            # Asegurar consistencia en la longitud de los arrays
            min_length = min(len(filtered_true_labels), len(filtered_predicted_labels), len(filtered_mcke_values))
            
            if min_length == 0:
                print("‚ùå Error: No hay datos v√°lidos para analizar.")
                return
                
            # Ajustar longitudes si es necesario
            if min_length < len(filtered_true_labels):
                print(f"   - Ajustando longitud de los datos a {min_length} eventos.")
                filtered_true_labels = filtered_true_labels[:min_length]
                filtered_predicted_labels = filtered_predicted_labels[:min_length]
                filtered_confidence_scores = filtered_confidence_scores[:min_length]
                filtered_probabilities = filtered_probabilities[:min_length]
                filtered_mcke_values = filtered_mcke_values[:min_length]
            
            # Usar los valores de mcke ya filtrados
            # Versi√≥n original (comentada):
            # ek_values = filtered_mcke_values
            
            # Versi√≥n usando valores originales:
            # Asegurarse de que todos los arrays tengan la misma longitud
            min_length = min(len(df['mcke'].values), len(filtered_mcke_values))
            ek_values = df['mcke'].values[:min_length]  # Usar los valores originales de mcke
            
            # Verificaci√≥n final de longitudes
            if len(ek_values) != len(filtered_true_labels) or len(ek_values) != len(filtered_predicted_labels):
                print("‚ùå Error: Inconsistencia en las longitudes de los arrays.")
                print(f"   - Valores de energ√≠a: {len(ek_values)}")
                print(f"   - Etiquetas reales: {len(filtered_true_labels)}")
                print(f"   - Predicciones: {len(filtered_predicted_labels)}")
                return
            
            # -------------------------------------------------------------------
            # 6.6.2. Inicializaci√≥n de estructuras de datos
            # -------------------------------------------------------------------
            print("   - Inicializando estructuras de datos...")
            
            # Diccionario para almacenar m√©tricas por tipo de part√≠cula
            metrics = {
                'e+': {'true': [], 'pred_e+': [], 'pred_e-': [], 'pred_gamma': [], 'ek_centers': []},
                'e-': {'true': [], 'pred_e+': [], 'pred_e-': [], 'pred_gamma': [], 'ek_centers': []},
                'gamma': {'true': [], 'pred_e+': [], 'pred_e-': [], 'pred_gamma': [], 'ek_centers': []}
            }
            
            # Mapeo de etiquetas a nombres de part√≠culas
            LABEL_TO_NAME = {0: 'e-', 1: 'e+', 2: 'gamma'}
            
            # -------------------------------------------------------------------
            # 6.6.3. An√°lisis por intervalos de energ√≠a
            # -------------------------------------------------------------------
            print("   - Procesando intervalos de energ√≠a...")
            
            # Diccionario para almacenar m√©tricas ROC por intervalo
            roc_metrics = {}
            
            for i, (low, high) in enumerate(EK_INTERVALS):
                # Determinar m√°scara para el intervalo de energ√≠a actual en MeV
                interval_str = f"{low}-{high} MeV" if high != float('inf') else f">{low} MeV"
                print(f"      - Procesando intervalo {interval_str}...")
                
                if high == float('inf'):
                    ek_mask = (ek_values >= low)  # √öltimo intervalo (sin l√≠mite superior)
                else:
                    ek_mask = (ek_values >= low) & (ek_values < high)
                
                # Saltar si no hay eventos en este intervalo
                if ek_mask.sum() == 0:
                    print(f"         No hay eventos en el intervalo {interval_str}")
                    continue
                
                # Extraer datos para este intervalo de energ√≠a
                # Versi√≥n original (comentada):
                # true_ek = filtered_true_labels[ek_mask]      # Etiquetas reales
                # pred_ek = filtered_predicted_labels[ek_mask]  # Predicciones
                # prob_ek = filtered_probabilities[ek_mask]     # Probabilidades
                
                # Versi√≥n usando valores originales:
                # Asegurarse de que la m√°scara tenga la longitud correcta
                min_length = min(len(true_labels), len(ek_mask))
                true_ek = true_labels[:min_length][ek_mask[:min_length]]
                
                min_length = min(len(predicted_labels), len(ek_mask))
                pred_ek = predicted_labels[:min_length][ek_mask[:min_length]]
                
                min_length = min(probabilities.shape[0], len(ek_mask))
                prob_ek = probabilities[:min_length][ek_mask[:min_length]]
                
                # Almacenar m√©tricas ROC para este intervalo
                roc_metrics[interval_str] = {
                    'true': true_ek,
                    'pred': pred_ek,
                    'prob': prob_ek,
                    'n_events': len(true_ek)
                }
                
                # Calcular el centro del intervalo para el eje X
                ek_center = (low + high) / 2 if high != float('inf') else low * 1.5
                
                # Calcular m√©tricas para cada tipo de part√≠cula
                for true_label, true_name in LABEL_TO_NAME.items():
                    # Crear m√°scara para la part√≠cula actual
                    part_mask = (true_ek == true_label)
                    total = part_mask.sum()
                    
                    if total > 0:  # Solo si hay part√≠culas de este tipo en el intervalo
                        # Calcular porcentajes de clasificaci√≥n
                        pred_counts = {
                            'e+': ((pred_ek[part_mask] == 1).sum() / total) * 100,
                            'e-': ((pred_ek[part_mask] == 0).sum() / total) * 100,
                            'gamma': ((pred_ek[part_mask] == 2).sum() / total) * 100
                        }
                        
                        # Almacenar m√©tricas
                        metrics[true_name]['true'].append(total)
                        metrics[true_name]['pred_e+'].append(pred_counts['e+'])
                        metrics[true_name]['pred_e-'].append(pred_counts['e-'])
                        metrics[true_name]['pred_gamma'].append(pred_counts['gamma'])
                        metrics[true_name]['ek_centers'].append(ek_center)
            
            # -------------------------------------------------------------------
            # 6.6.4. Generaci√≥n de curvas ROC por intervalo de energ√≠a
            # -------------------------------------------------------------------
            print("\n   - Generando curvas ROC por intervalo de energ√≠a...")
            
            # Configuraci√≥n de colores para los intervalos
            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
            
            # Tipos de part√≠culas para las curvas ROC
            particle_pairs = [
                ('e+', 'gamma', 'Positrones vs Gammas'),
                ('gamma', 'e-', 'Gammas vs Electrones'),
                ('e-', 'gamma', 'Electrones vs Gammas'),
                ('e+', 'e-', 'Positrones vs Electrones')  
            ]
            
            for true_particle, false_particle, title in particle_pairs:
                plt.figure(figsize=(10, 8))
                
                # Mapeo de etiquetas
                true_label = {'e+': 1, 'e-': 0, 'gamma': 2}[true_particle]
                false_label = {'e+': 1, 'e-': 0, 'gamma': 2}[false_particle]
                
                # Para cada intervalo de energ√≠a
                for i, (interval_str, data) in enumerate(roc_metrics.items()):
                    if data['n_events'] < 10:  # M√≠nimo de eventos para calcular ROC
                        continue
                        
                    # Filtrar solo las part√≠culas de inter√©s
                    mask = (data['true'] == true_label) | (data['true'] == false_label)
                    if mask.sum() == 0:
                        continue
                        
                    true_labels = (data['true'][mask] == true_label).astype(int)
                    prob = data['prob'][mask, true_label if true_particle != 'gamma' else 2]
                    
                    # M√©todo 1: C√°lculo manual con 100 umbrales (m√°s suave)
                    thresholds = np.linspace(0, 1, 101)
                    tpr_vals = []
                    fpr_vals = []
                    
                    for thresh in thresholds:
                        # Predicci√≥n seg√∫n el umbral
                        pred = (prob >= thresh).astype(int)
                        
                        # Calcular VP, VN, FP, FN
                        vp = np.sum((true_labels == 1) & (pred == 1))
                        fp = np.sum((true_labels == 0) & (pred == 1))
                        vn = np.sum((true_labels == 0) & (pred == 0))
                        fn = np.sum((true_labels == 1) & (pred == 0))
                        
                        # Calcular TPR y FPR
                        tpr_val = vp / (vp + fn) if (vp + fn) > 0 else 0
                        fpr_val = fp / (fp + vn) if (fp + vn) > 0 else 0
                        
                        tpr_vals.append(tpr_val)
                        fpr_vals.append(fpr_val)
                    
                    # M√©todo alternativo: Usando roc_curve de scikit-learn (menos suave)
                    # fpr, tpr, _ = roc_curve(true_labels, prob)
                    # tpr_vals, fpr_vals = tpr, fpr
                    
                    # Calcular AUC
                    roc_auc = auc(fpr_vals, tpr_vals)
                    
                    # Contar part√≠culas reales en el intervalo actual
                    n_true_pos = (data['true'][mask] == true_label).sum()
                    n_true_neg = (data['true'][mask] == false_label).sum()
                    
                    # Graficar con escala logar√≠tmica en el eje Y
                    plt.semilogy(tpr_vals, fpr_vals, color=colors[i % len(colors)], lw=2,
                               label=f'{interval_str} (AUC={roc_auc:.3f}, {true_particle}:{n_true_pos}, {false_particle}:{n_true_neg})')
                
                # Configuraci√≥n del gr√°fico
                plt.xlim([0.5, 1.0])  # Rango de 0.5 a 1.0 en el eje X
                plt.ylim([1e-4, 1.05])  # Escala logar√≠tmica en el eje Y
                plt.xlabel('TPR (True Positive Rate)')
                plt.ylabel('FPR (False Positive Rate, escala log)')
                plt.title(f'Curvas ROC por intervalo de energ√≠a: {title}')
                plt.legend(loc="lower right")
                plt.grid(True, which="both", alpha=0.3)
                
                # Guardar la figura y mostrarla
                filename = f'roc_{true_particle}_vs_{false_particle}_by_energy.png'.replace('+', 'p')
                plt.tight_layout()
                plt.savefig(f'{plots_dir}/{filename}', dpi=300, bbox_inches='tight')
                print(f"      - Gr√°fico guardado: {filename}")
                plt.show()
                plt.close()
            
            # -------------------------------------------------------------------
            # 6.6.5. Generaci√≥n de gr√°ficos de eficiencia
            # -------------------------------------------------------------------
            print("   - Generando gr√°ficos de eficiencia...")
            
            for particle in ['e+', 'e-', 'gamma']:
                if not metrics[particle]['ek_centers']:  # Saltar si no hay datos
                    continue
                    
                # Configurar figura
                plt.figure(figsize=(14, 8))
                
                # Usar los intervalos de energ√≠a ya definidos en EK_INTERVALS
                # Reemplazamos float('inf') por 10.0 para la visualizaci√≥n
                energy_intervals = [(low, high if high != float('inf') else 10.0) 
                                 for low, high in EK_INTERVALS]
                
                # Colores m√°s vibrantes para los intervalos
                interval_colors = ['#ffcdd2', '#c8e6c9', '#bbdefb']
                
                # Etiquetas personalizadas para los intervalos
                interval_labels = ['0-1 MeV', '1-3 MeV', '>3 MeV']
                
                # Dibujar √°reas sombreadas para cada intervalo de energ√≠a
                for i, (e_min, e_max) in enumerate(energy_intervals):
                    plt.axvspan(e_min, e_max, alpha=0.3, color=interval_colors[i], 
                              label=interval_labels[i])
                
                # Ordenar datos por energ√≠a cin√©tica
                sorted_idx = np.argsort(metrics[particle]['ek_centers'])
                ek_sorted = np.array(metrics[particle]['ek_centers'])[sorted_idx]
                
                # Graficar tasa de aciertos (identificaciones correctas)
                particle_name = {'e+': 'Positr√≥n', 'e-': 'Electr√≥n', 'gamma': 'Gamma'}[particle]
                plt.plot(ek_sorted, 
                        np.array(metrics[particle][f'pred_{particle}'])[sorted_idx], 
                        'o-', color='#2ecc71', linewidth=2.5, markersize=8,
                        label=f'Correcto: {particle_name}')
                
                # Graficar tasas de falsas identificaciones
                for other in ['e+', 'e-', 'gamma']:
                    if other != particle and metrics[particle][f'pred_{other}']:
                        style = 'o--'
                        color = None
                        particle_names = {'e+': 'Positr√≥n', 'e-': 'Electr√≥n', 'gamma': 'Gamma'}
                        label = f'Error: {particle_names[other]}'
                        
                        if other == 'e+':
                            color = '#e74c3c'  # Rojo
                        elif other == 'e-':
                            color = '#3498db'  # Azul
                        else:  # gamma
                            color = '#9b59b6'  # P√∫rpura
                        
                        plt.plot(ek_sorted, 
                                np.array(metrics[particle][f'pred_{other}'])[sorted_idx],
                                style, color=color, linewidth=1.5, markersize=5,
                                label=label, alpha=0.8)
                
                # Configuraci√≥n del gr√°fico
                particle_title = {'e+': 'Positrones', 'e-': 'Electrones', 'gamma': 'Gammas'}[particle]
                plt.title(f'Identificaci√≥n de {particle_title} por intervalo de energ√≠a', 
                         fontsize=14, pad=15, fontweight='bold')
                plt.xlabel('Energ√≠a cin√©tica (MeV)', fontsize=14, labelpad=12)
                plt.ylabel('Porcentaje de eventos (%)', fontsize=14, labelpad=12)
                plt.grid(True, alpha=0.2, linestyle='--', which='both')
                
                # Ajustar l√≠mites del eje Y y X
                plt.ylim(-2, 102)
                plt.xlim(0, max(ek_sorted) * 1.1)  # 10% de margen en el eje X
                
                # A√±adir leyenda dentro del gr√°fico (posici√≥n vertical entre 40% y 60%)
                plt.legend(loc='center right', frameon=True, framealpha=0.9,
                         fontsize=10, bbox_to_anchor=(0.98, 0.5))
                
                # Mejorar la apariencia general
                plt.gca().spines['top'].set_visible(False)
                plt.gca().spines['right'].set_visible(False)
                plt.tight_layout()
                
                # Guardar la figura con metadatos en la carpeta Plots
                output_file = f'{plots_dir}/eficiencia_por_energia_{particle}.png'
                plt.savefig(output_file, dpi=300, bbox_inches='tight', 
                            metadata={'CreationDate': None, 'Software': 'Python/Matplotlib'})
                print(f'   - Gr√°fico guardado: {output_file}')
                plt.show()
                plt.close()
            
            # -------------------------------------------------------------------
            # 6.6.5. AN√ÅLISIS DE PRECISI√ìN POR INTERVALO DE ENERG√çA
            # -------------------------------------------------------------------
            print("\nüìä Analizando precisi√≥n por intervalo de energ√≠a...")
            
            # Diccionario para almacenar m√©tricas por intervalo
            interval_metrics = {}
            
            for i, (low, high) in enumerate(EK_INTERVALS):
                # -------------------------------------------------------------------
                # 6.6.5.1. Filtrar eventos por intervalo de energ√≠a
                # -------------------------------------------------------------------
                if high == float('inf'):
                    ek_mask = (ek_values >= low)  # √öltimo intervalo (sin l√≠mite superior)
                    interval_str = f">{low:.1f} MeV"
                else:
                    ek_mask = (ek_values >= low) & (ek_values < high)
                    interval_str = f"{low:.1f}-{high:.1f} MeV"
                
                # Saltar si no hay eventos en este intervalo
                if ek_mask.sum() == 0:
                    print(f"\n‚ö†Ô∏è  No hay eventos en el intervalo {interval_str}")
                    continue
                
                # -------------------------------------------------------------------
                # 6.6.5.2. Calcular m√©tricas para el intervalo actual
                # -------------------------------------------------------------------
                true_ek = filtered_true_labels[ek_mask]      # Etiquetas reales filtradas
                pred_ek = filtered_predicted_labels[ek_mask]  # Predicciones filtradas
                total_events = len(true_ek)         # Total de eventos
                print(f"\n[DEBUG] total_events (true_ek) = {total_events}")
                
                # Calcular matriz de confusi√≥n
                cm_ek = confusion_matrix(true_ek, pred_ek, labels=[0, 1, 2])
                correct = np.sum(cm_ek.diagonal())
                accuracy = correct / total_events
                
                # Almacenar m√©tricas para resumen final
                interval_metrics[interval_str] = {
                    'total': total_events,
                    'accuracy': accuracy,
                    'cm': cm_ek
                }
                
                # -------------------------------------------------------------------
                # 6.6.5.3. Mostrar resultados detallados por consola
                # -------------------------------------------------------------------
                print(f"\nüîç Intervalo de energ√≠a {interval_str}:")
                print(f"   - Total de eventos: {total_events}")
                print(f"   - Precisi√≥n global: {accuracy:.4f} ({accuracy*100:.2f}%)")
                
                # Funci√≥n para calcular y mostrar precisi√≥n por part√≠cula
                def print_particle_metrics(particle_name, particle_idx):
                    total_particle = np.sum(cm_ek[particle_idx, :])
                    if total_particle > 0:
                        acc = cm_ek[particle_idx, particle_idx] / total_particle
                        print(f"   - Precisi√≥n para {particle_name}: {acc:.4f} ({acc*100:.2f}%)")
                    else:
                        print(f"   - No hay {particle_name} en este intervalo")
                
                # Mostrar m√©tricas para cada tipo de part√≠cula
                print_particle_metrics("electrones", 0)
                print_particle_metrics("positrones", 1)
                print_particle_metrics("gammas", 2)
                
                # Mostrar matriz de confusi√≥n reducida
                if total_events > 0:
                    print("\n   Matriz de confusi√≥n (fila: real, col: pred):")
                    print(f"   {'':<10} {'e-':<8} {'e+':<8} {'gamma':<8}")
                    for i, (true_name, true_idx) in enumerate([('e-', 0), ('e+', 1), ('gamma', 2)]):
                        row = [f"{cm_ek[true_idx, pred_idx]:<8}" for pred_idx in range(3)]
                        print(f"   {true_name:<10} {' '.join(row)}")
            
            # -------------------------------------------------------------------
            # 6.6.5.4. Mostrar resumen de m√©tricas por intervalo
            # -------------------------------------------------------------------
            if interval_metrics:
                print("\n" + "="*80)
                print("üìã RESUMEN DE PRECISI√ìN POR INTERVALO DE ENERG√çA")
                print("="*80)
                print(f"{'Intervalo de energ√≠a':<40} {'Eventos':<10} {'Precisi√≥n':<15}")
                print("-"*80)
                
                # Mostrar m√©tricas para cada intervalo de energ√≠a
                for interval, metrics in interval_metrics.items():
                    print(f"{interval:<40} {metrics['total']:<10} {metrics['accuracy']*100:>6.2f}%")
                
                print("="*80 + "\n")
            
            # ===================================================================
            # 6.7. AN√ÅLISIS DETALLADO POR EVENTO
            # ===================================================================
            print(f"\n{'='*80}")
            print(f"üìä AN√ÅLISIS DETALLADO POR EVENTO - {os.path.basename(input_file)}")
            print(f"{'='*80}")
            
            # Inicializar lista para almacenar resultados detallados
            results = []
            
            # Crear m√°scara para eventos que superan el umbral
            if prob_threshold > 0.0:
                above_threshold = np.max(filtered_probabilities, axis=1) >= prob_threshold
                valid_indices = np.where(above_threshold)[0]
                print(f"\nüîç Aplicando umbral de confianza del {prob_threshold*100:.0f}%")
                print(f"   - Eventos que superan el umbral: {len(valid_indices)}/{len(df)} ({(len(valid_indices)/len(df))*100:.1f}%)")
                print(f"   - Rango de event_number en eventos seleccionados: {df['event_number'].iloc[valid_indices].min()} a {df['event_number'].iloc[valid_indices].max()}")
            else:
                valid_indices = range(len(df))
                print(f"\nüîç Procesando todos los {len(df)} eventos (sin umbral de confianza)")
                print(f"   - Rango de event_number: {df['event_number'].min()} a {df['event_number'].max()}")
            
            # -------------------------------------------------------------------
            # 6.7.1. PROCESAMIENTO DE EVENTOS V√ÅLIDOS
            # -------------------------------------------------------------------
            print(f"\nüîç Procesando {len(valid_indices)} eventos...")
            start_time = time.time()
            
            # Recorrer solo los eventos que superan el umbral
            for i, idx in enumerate(valid_indices):
                # Obtener informaci√≥n b√°sica del evento
                event_idx = i + 1  # √çndices empiezan en 1 para mejor legibilidad
                original_id = int(filtered_event_numbers[i])  # Usar el event_number filtrado
                true_pdg = int(df['mcpdg'].iloc[idx]) if 'mcpdg' in df.columns else None
                
                # Mostrar los valores en cada iteraci√≥n
                #print(f"event_idx: {event_idx}, original_id: {original_id}")
                
                # Obtener probabilidades y predicci√≥n
                event_probs = filtered_probabilities[idx]
                max_prob_idx = np.argmax(event_probs)
                confidence = event_probs[max_prob_idx]
                predicted_particle = LABEL_TO_PARTICLE.get(max_prob_idx, "Desconocido")
                
                # Mapear etiquetas verdaderas
                true_particle = PDG_TO_PARTICLE.get(true_pdg, f"PDG {true_pdg}") if true_pdg is not None else "Desconocido"
                
                # Validar predicci√≥n si hay etiqueta verdadera
                is_correct = False
                if true_pdg is not None:
                    true_label_num = None
                    if true_pdg == 11: true_label_num = 0    # Electr√≥n
                    elif true_pdg == -11: true_label_num = 1  # Positr√≥n
                    elif true_pdg == 22: true_label_num = 2   # Gamma
                    
                    is_correct = (max_prob_idx == true_label_num) if true_label_num is not None else False
                    # La variable is_correct se mantiene en el diccionario de resultados
                
                # Crear diccionario de probabilidades
                prob_dict = {p: prob for p, prob in zip(LABEL_TO_PARTICLE.values(), event_probs)}
                
                # Almacenar resultados
                results.append({
                    'event_idx': event_idx,  # √çndice despu√©s del filtrado
                    'original_id': original_id,  # ID original del evento
                    'predicted': predicted_particle,
                    'confidence': confidence,
                    'true': true_particle,
                    'true_pdg': true_pdg,
                    'is_correct': is_correct,
                    'probabilities': prob_dict
                })
        
            # -------------------------------------------------------------------
            # 6.7.2 PRESENTACI√ìN DE RESULTADOS
            # -------------------------------------------------------------------
            print("\n" + "="*80)
            print("üìä RESUMEN DE RESULTADOS".center(80))
            print("="*80)
            
            # Configuraci√≥n de paginaci√≥n
            events_per_page = 5
            current_page = 0
            total_events = len(results)
            total_pages = (total_events + events_per_page - 1) // events_per_page
            
            # Mostrar resumen de la primera p√°gina
            print(f"\nüìÑ Mostrando p√°gina 1 de {total_pages} "
                f"(eventos 1 a {min(events_per_page, total_events)} de {total_events})")
            
            # Mostrar resultados por p√°ginas
            while current_page < total_pages:
                # Calcular √≠ndices de la p√°gina actual
                start_idx = current_page * events_per_page
                end_idx = min(start_idx + events_per_page, total_events)
                current_results = results[start_idx:end_idx]
                
                # Mostrar encabezado de p√°gina mejorado
                page_info = f"P√ÅGINA {current_page + 1}/{total_pages} - EVENTOS {start_idx + 1}-{end_idx} de {total_events}"
                print("\n" + "‚ïê" * 80)
                print(f"üìä {page_info:^76} üìä")
                print("")
                print("")
                print("")
                print("")
                print("")
                print("")
                
                # Mostrar eventos de la p√°gina actual en formato compacto
                for result in current_results:
                    # Encabezado del evento con informaci√≥n b√°sica
                    status = f"‚úÖ" if result['is_correct'] else ("‚ùå" if result['true_pdg'] is not None else "")
                    print(f"\n‚ïî{'‚ïê'*78}‚ïó")
                    print(f"‚ïë üìå EVENTO #{result['event_idx']:<3} (ID original: {result['original_id']:<5}) | {result['predicted']:<15} | "
                        f"Conf: {result['confidence']*100:5.1f}% {status:>3} ‚ïë")
                    
                    # Informaci√≥n detallada en una sola l√≠nea
                    if result['true_pdg'] is not None:
                        print(f"‚ïë {'Real: ' + result['true'] + ' (PDG:' + str(result['true_pdg']) + ')':<76} ‚ïë")
                    
                    # Barras de probabilidad compactas
                    print(f"‚ï†{'‚ïê'*78}‚ï£")
                    probs = [(p, prob) for p, prob in result['probabilities'].items()]
                    print("‚ïë ", end="")
                    for i, (particle, prob) in enumerate(probs):
                        bar = '‚ñà' * int(round(prob * 10)) + ' ' * (10 - int(round(prob * 10)))
                        print(f"{particle[0]}:{prob*100:3.0f}%|{bar}| ", end="" if i < len(probs)-1 else "‚ïë\n")
                    print(f"‚ïö{'‚ïê'*78}‚ïù")
                
                # Opciones de navegaci√≥n
                print("\n" + "="*80)
                print("OPCIONES:".center(80))
                print("  ‚Ä¢ Presiona Enter para ver la siguiente p√°gina")
                print("  ‚Ä¢ 'a' + Enter para ver la p√°gina anterior" if current_page > 0 else "")
                print("  ‚Ä¢ 's' + Enter para salir")
                print(f"  ‚Ä¢ N√∫mero de evento (1-{total_events}) para ver detalles")
                print("="*80)
                
                user_input = input("\n¬øQu√© deseas hacer? ").strip().lower()
                
                # Procesar entrada del usuario
                if user_input == 's':
                    break
                elif user_input == 'a' and current_page > 0:
                    current_page -= 2  # Se incrementar√° 1 despu√©s
                elif user_input.isdigit():
                    event_num = int(user_input) - 1
                    if 0 <= event_num < total_events:
                        # Mostrar evento espec√≠fico
                        result = results[event_num]
                        clear_output(wait=True)
                        print("\n" + "="*80)
                        print(f"üìã DETALLES DEL EVENTO #{result['event_idx']} (ID original: {result['original_id']})".center(80))
                        print("="*80)
                        
                        # Mostrar informaci√≥n detallada
                        print(f"\nüîç CLASIFICACI√ìN:")
                        print(f"  {'Predicci√≥n:':<18} {result['predicted']}")
                        print(f"  {'Confianza:':<18} {result['confidence']*100:.1f}%")
                        
                        if result['true_pdg'] is not None:
                            print(f"\n‚úÖ VERIFICACI√ìN:")
                            print(f"  {'Part√≠cula real:':<18} {result['true']}")
                            print(f"  {'PDG:':<18} {result['true_pdg']}")
                            status = "‚úÖ CORRECTO" if result['is_correct'] else "‚ùå INCORRECTO"
                            print(f"  {'Estado:':<18} {status}")
                        
                        print("\nüìä DISTRIBUCI√ìN DE PROBABILIDADES:")
                        for p, prob in result['probabilities'].items():
                            bar_len = int(prob * 20)
                            print(f"  {p + ':':<12} {prob*100:5.1f}% |{'‚ñà'*bar_len}{'‚ñë'*(20-bar_len)}|")
                        
                        # Mostrar histogramas si est√°n disponibles
                        if show_histograms and histo_dir is not None:
                            print("\nüìä VISUALIZACI√ìN DE HISTOGRAMAS:")
                            try:
                                # Usar el ID original para cargar los histogramas
                                original_id = result['original_id']
                                event_dir = histo_dir.get(f"event_{original_id}")
                                
                                if event_dir:
                                    # Obtener histogramas desde el directorio del evento
                                    hist_zp = event_dir.get("hr_zp")
                                    hist_zm = event_dir.get("hr_zm")
                                else:
                                    # Mantener compatibilidad con el formato antiguo
                                    hist_zp = histo_dir.get(f"hr_zp_evt{original_id}")
                                    hist_zm = histo_dir.get(f"hr_zm_evt{original_id}")
                                
                                if hist_zp is not None and hist_zm is not None:
                                    # Mostrar los histogramas con el original_id
                                    display_histograms(
                                        original_id,
                                        hist_zp,
                                        hist_zm,
                                        result['predicted'],
                                        result['true'] if result['true_pdg'] is not None else None,
                                        result['confidence']
                                    )
                                else:
                                    print("  ‚ö†Ô∏è  No se encontraron los histogramas para este evento")
                            except Exception as e:
                                print(f"  ‚ö†Ô∏è  Error al cargar los histogramas: {str(e)}")
                        
                        input("\n‚èé Presiona Enter para continuar...")
                        continue
                
                # Avanzar a la siguiente p√°gina
                current_page += 1
            
            # -------------------------------------------------------------------
            # 6.9. FINALIZACI√ìN
            # -------------------------------------------------------------------
            print("\n" + "="*80)
            print("AN√ÅLISIS COMPLETADO EXITOSAMENTE".center(80))
            print("="*80)
            print(f"\n‚úì Procesamiento finalizado a las: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            print("="*80 + "\n")
        
    except Exception as e:
        print(f"Ocurri√≥ un error inesperado al procesar el archivo ROOT: {e}")
    finally:
        # Asegurarse de cerrar el archivo ROOT
        if file is not None:
            file.close()

if __name__ == "__main__":
    # Configuraci√≥n del an√°lisis
    CONFIG = {
        'show_histograms': True,  # Mostrar histogramas interactivos
        'max_events': None,       # N√∫mero m√°ximo de eventos a procesar (None = todos)
        'prob_threshold': 0.6     # Umbral de probabilidad (0.0 = desactivado, 1.0 = m√°ximo)
    }
    
    # Validar umbral
    if not (0.0 <= CONFIG['prob_threshold'] < 1.0):
        print("Error: El umbral de probabilidad debe estar entre 0.0 y 0.99")
        sys.exit(1)
    
    # Verificar si los archivos de modelo y scaler existen
    if not os.path.exists(MODEL_PATH):
        print(f"Error: Archivo de modelo '{MODEL_PATH}' no encontrado. Aseg√∫rate de que el modelo est√© entrenado y guardado.")
    elif not os.path.exists(SCALER_PATH):
        print(f"Error: Archivo de scaler '{SCALER_PATH}' no encontrado. Aseg√∫rate de que el scaler se haya guardado durante el entrenamiento.")
    elif not os.path.exists(INPUT_ROOT_FILE):
        print(f"Error: Archivo de entrada '{INPUT_ROOT_FILE}' no encontrado. Verifica la ruta y el nombre del archivo.")
    else:
        # Llamar a la funci√≥n con la configuraci√≥n
        classify_events(
            model_path=MODEL_PATH,
            scaler_path=SCALER_PATH,
            input_file=INPUT_ROOT_FILE,
            tree_name=TREE_NAME,
            feature_columns=FEATURE_COLUMNS,
            max_events=CONFIG['max_events'],
            show_histograms_flag=CONFIG['show_histograms'],
            prob_threshold=CONFIG['prob_threshold']
        )